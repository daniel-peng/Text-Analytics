{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analytics Group Assignment 2\n",
    "### ArjunVarma_AnyingLi_YuanzhuoPeng_JiaqiuWang_NimishAmlathe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranjor/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "from patsy import dmatrices\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>votes_cool</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>votes_useful</th>\n",
       "      <th>Cheap</th>\n",
       "      <th>Moderate</th>\n",
       "      <th>Expensive</th>\n",
       "      <th>VeryExpensive</th>\n",
       "      <th>American</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>...</th>\n",
       "      <th>Indian</th>\n",
       "      <th>Italian</th>\n",
       "      <th>Greek</th>\n",
       "      <th>Mediterranean</th>\n",
       "      <th>Mexican</th>\n",
       "      <th>Thai</th>\n",
       "      <th>Vietnamese</th>\n",
       "      <th>Others</th>\n",
       "      <th>Review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>This location is out of business. I drove by i...</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>= = = = = = CLOSED = = = = = =This JB s locati...</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>This is just a basic (albeit mini) chain greas...</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Whenever I offer to take my mom out to lunch s...</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>If I say it wasn t as bad as I was expecting i...</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars  votes_cool  votes_funny  votes_useful  Cheap  Moderate  Expensive  \\\n",
       "0      1           0            0             0      1         0          0   \n",
       "1      2           2            2             2      1         0          0   \n",
       "2      4           0            0             1      1         0          0   \n",
       "3      3           0            1             2      1         0          0   \n",
       "4      3           7            9             9      1         0          0   \n",
       "\n",
       "   VeryExpensive  American  Chinese   ...    Indian  Italian  Greek  \\\n",
       "0              0         0        0   ...         0        0      0   \n",
       "1              0         0        0   ...         0        0      0   \n",
       "2              0         0        0   ...         0        0      0   \n",
       "3              0         0        0   ...         0        0      0   \n",
       "4              0         0        0   ...         0        0      0   \n",
       "\n",
       "   Mediterranean  Mexican  Thai  Vietnamese  Others  \\\n",
       "0              0        0     0           0       1   \n",
       "1              0        0     0           0       1   \n",
       "2              0        0     0           0       1   \n",
       "3              0        0     0           0       1   \n",
       "4              0        0     0           0       1   \n",
       "\n",
       "                                              Review  rating  \n",
       "0  This location is out of business. I drove by i...     Low  \n",
       "1  = = = = = = CLOSED = = = = = =This JB s locati...     Low  \n",
       "2  This is just a basic (albeit mini) chain greas...    High  \n",
       "3  Whenever I offer to take my mom out to lunch s...     Low  \n",
       "4  If I say it wasn t as bad as I was expecting i...     Low  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp = pd.read_csv('Yelp Data Restaurant Reviews Ratings.csv')\n",
    "yelp['rating'] = yelp['stars'].map(lambda x: 'High' if x >3  else 'Low')\n",
    "yelp[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['stars', 'votes_cool', 'votes_funny', 'votes_useful', 'Cheap',\n",
       "       'Moderate', 'Expensive', 'VeryExpensive', 'American', 'Chinese',\n",
       "       'French', 'Japanese', 'Indian', 'Italian', 'Greek', 'Mediterranean',\n",
       "       'Mexican', 'Thai', 'Vietnamese', 'Others', 'Review', 'rating'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task A. Ignore the text (reviews) and run a classification model with the numeric data (you can use standard methods like logistic regression, k-nearest neighbors or anything else). What is the best accuracy of your model with numeric data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>votes_cool</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>votes_useful</th>\n",
       "      <th>Cheap</th>\n",
       "      <th>Moderate</th>\n",
       "      <th>Expensive</th>\n",
       "      <th>VeryExpensive</th>\n",
       "      <th>American</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>...</th>\n",
       "      <th>Indian</th>\n",
       "      <th>Italian</th>\n",
       "      <th>Greek</th>\n",
       "      <th>Mediterranean</th>\n",
       "      <th>Mexican</th>\n",
       "      <th>Thai</th>\n",
       "      <th>Vietnamese</th>\n",
       "      <th>Others</th>\n",
       "      <th>Review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I ll be honest...I m not a food connoisseur  b...</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Made reservations for 5:30 PM on a Saturday ni...</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This place has an awesome Happy Hour. The envi...</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars  votes_cool  votes_funny  votes_useful  Cheap  Moderate  Expensive  \\\n",
       "0      5           0            0             0      0         1          0   \n",
       "1      2           0            1             3      0         0          1   \n",
       "2      5           0            1             1      0         1          0   \n",
       "\n",
       "   VeryExpensive  American  Chinese   ...    Indian  Italian  Greek  \\\n",
       "0              0         1        0   ...         0        0      0   \n",
       "1              0         1        0   ...         0        0      0   \n",
       "2              0         1        0   ...         0        0      0   \n",
       "\n",
       "   Mediterranean  Mexican  Thai  Vietnamese  Others  \\\n",
       "0              0        0     0           0       0   \n",
       "1              0        0     0           0       0   \n",
       "2              0        0     0           0       0   \n",
       "\n",
       "                                              Review  rating  \n",
       "0  I ll be honest...I m not a food connoisseur  b...    High  \n",
       "1  Made reservations for 5:30 PM on a Saturday ni...     Low  \n",
       "2  This place has an awesome Happy Hour. The envi...    High  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take only a random subset of 2000 rows\n",
    "yelp_subset = yelp.sample(frac=.1,random_state=5)\n",
    "yelp_subset = yelp_subset.reset_index()\n",
    "yelp_subset = yelp_subset.drop('index',axis=1)\n",
    "yelp_subset[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split train and test data\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit \n",
    "\n",
    "y = yelp_subset['rating'].map(lambda y: 1 if y == 'High'  else 0)\n",
    "\n",
    "X = yelp_subset.drop(['stars','Review','rating'], axis=1)\n",
    "\n",
    "Review = yelp_subset['Review']\n",
    "\n",
    "sss = StratifiedShuffleSplit(y, test_size=0.3, random_state=1)\n",
    "for train_index, test_index in sss:\n",
    "    break\n",
    "\n",
    "train_x, train_y,train_review = X.values[train_index],y.values[train_index],Review[train_index]\n",
    "test_x, test_y, test_review = X.values[test_index], y.values[test_index],Review[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy score: 0.695714285714\n",
      "Test set accuracy score: 0.703333333333\n"
     ]
    }
   ],
   "source": [
    "#knn model with numerical inputs only\n",
    "from sklearn import neighbors\n",
    "modelknn = neighbors.KNeighborsClassifier(n_neighbors=15, weights='uniform', p=2)\n",
    "modelknn.fit(train_x,train_y)\n",
    "\n",
    "from sklearn import metrics\n",
    "prediction_on_training = modelknn.predict(train_x)\n",
    "print \"Train set accuracy score:\", metrics.accuracy_score(train_y, prediction_on_training)\n",
    "\n",
    "predicted_classes = modelknn.predict(test_x)\n",
    "print \"Test set accuracy score:\", metrics.accuracy_score(test_y, predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy score: 0.692857142857\n",
      "Test set accuracy score: 0.701666666667\n"
     ]
    }
   ],
   "source": [
    "#logistic regression with numerical inputs only\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "modellog = LogisticRegression()\n",
    "modellog.fit(train_x, train_y)\n",
    "\n",
    "from sklearn import metrics\n",
    "prediction_on_training = modellog.predict(train_x)\n",
    "print \"Train set accuracy score:\", metrics.accuracy_score(train_y, prediction_on_training)\n",
    "\n",
    "predicted_classes = modellog.predict(test_x)\n",
    "print \"Test set accuracy score:\", metrics.accuracy_score(test_y, predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy score: 0.687142857143\n",
      "Test set accuracy score: 0.686666666667\n"
     ]
    }
   ],
   "source": [
    "#naive bayes with numerical inputs only\n",
    "from sklearn import naive_bayes\n",
    "modelnby = naive_bayes.MultinomialNB()\n",
    "modelnby.fit(train_x, train_y)\n",
    "\n",
    "from sklearn import metrics\n",
    "prediction_on_training = modelnby.predict(train_x)\n",
    "print \"Train set accuracy score:\", metrics.accuracy_score(train_y, prediction_on_training)\n",
    "\n",
    "predicted_classes = modelnby.predict(test_x)\n",
    "print \"Test set accuracy score:\", metrics.accuracy_score(test_y, predicted_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the best accuracy with using only numeric data for prediction is about 70.3% on test data with k nearest neighbor model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task B. Perform a supervised classification on a subset of the corpus using the reviews only. You can write your code in Python or R. What accuracy do you get from this text mining exercise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def lemmatize(tokens,wnl):\n",
    "    lem=[]\n",
    "    for item in tokens:\n",
    "        lem.append(wnl.lemmatize(item))\n",
    "    return lem\n",
    "\n",
    "def my_tokenizer(text):\n",
    "    text = \"\".join([ch for ch in text if ch not in string.punctuation])\n",
    "    text = re.sub('[0-9]+','',text)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    #result = stem_tokens(tokens, stemmer)\n",
    "    #result = lemmatize(tokens, wnl)\n",
    "    result = tokens\n",
    "    return result\n",
    "    \n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=3,max_df=0.9,tokenizer=my_tokenizer,\n",
    " ngram_range=(1, 2), \n",
    " stop_words='english',\n",
    " strip_accents='unicode',max_features=200)\n",
    "\n",
    "text_1 = vectorizer.fit_transform(train_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: Multinomial Naive Bayes\n",
      "\n",
      "The accuracy for this classifier is 0.72\n"
     ]
    }
   ],
   "source": [
    "from nltk import NaiveBayesClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "text_2 = vectorizer.transform(test_review)\n",
    "\n",
    "nb =  MultinomialNB().fit(text_1, train_y)\n",
    "\n",
    "y_nb_predicted = nb.predict(text_2)\n",
    "\n",
    "\n",
    "print \"MODEL: Multinomial Naive Bayes\\n\"\n",
    "\n",
    "print 'The accuracy for this classifier is ' + str(metrics.accuracy_score(test_y, y_nb_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the accuracy with using only review data for prediction is about 72% on test data with Multinomial Naive Bayes Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task C. Combine the numeric data and the text classification model (in task B) to create a “hybrid” model. It is your task to figure out how to do this. Now run this hybrid classification model and compare the results with those in A and B. Does the numeric data add to the predictive power relative to text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The top 50 most informative features: \n",
      "perfect,times,hour,meal,people,rice,right,wait,tacos,mexican,got,sauce,salad,definitely,order,burger,dinner,eat,atmosphere,excellent,cheese,staff,bar,favorite,ordered,phoenix,happy,pizza,awesome,friendly,lunch,try,fresh,little,nice,amazing,restaurant,menu,delicious,chicken,time,really,best,love,like,service,place,good,food,great\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from operator import itemgetter\n",
    "\n",
    "N = 50\n",
    "vocabulary = np.array([t for t, i in sorted(vectorizer.vocabulary_.iteritems(), key=itemgetter(1))])\n",
    "\n",
    "topN = np.argsort(nb.coef_[0])[-N:]\n",
    "\n",
    "print \"\\nThe top %d most informative features: \\n%s\" % (N, ','.join(vocabulary[topN]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>votes_cool</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>votes_useful</th>\n",
       "      <th>Cheap</th>\n",
       "      <th>Moderate</th>\n",
       "      <th>Expensive</th>\n",
       "      <th>VeryExpensive</th>\n",
       "      <th>American</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>French</th>\n",
       "      <th>...</th>\n",
       "      <th>time</th>\n",
       "      <th>really</th>\n",
       "      <th>best</th>\n",
       "      <th>love</th>\n",
       "      <th>like</th>\n",
       "      <th>service</th>\n",
       "      <th>place</th>\n",
       "      <th>good</th>\n",
       "      <th>food</th>\n",
       "      <th>great</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   votes_cool  votes_funny  votes_useful  Cheap  Moderate  Expensive  \\\n",
       "0           0            0             0      0         1          0   \n",
       "1           0            1             3      0         0          1   \n",
       "2           0            1             1      0         1          0   \n",
       "3           0            0             0      0         0          0   \n",
       "4           0            0             0      0         1          0   \n",
       "\n",
       "   VeryExpensive  American  Chinese  French  ...    time  really  best  love  \\\n",
       "0              0         1        0       0  ...       0       0     0     0   \n",
       "1              0         1        0       0  ...       0       0     0     0   \n",
       "2              0         1        0       0  ...       0       0     0     0   \n",
       "3              1         1        0       0  ...       0       0     0     0   \n",
       "4              0         1        0       0  ...       0       0     0     0   \n",
       "\n",
       "   like  service  place  good  food  great  \n",
       "0     0        0      0     0     0      0  \n",
       "1     0        0      0     0     0      0  \n",
       "2     0        0      0     0     0      0  \n",
       "3     0        0      0     0     0      0  \n",
       "4     0        0      0     0     0      0  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_informative = vocabulary[topN]\n",
    "\n",
    "for w in most_informative:\n",
    "    X[w]= 0\n",
    "\n",
    "def create_features(tokens,i):\n",
    "    document_words = set(tokens)\n",
    "    features = {}\n",
    "    for word in most_informative:\n",
    "        if word in document_words:\n",
    "            X.loc[i,word] = 1\n",
    "        \n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>votes_cool</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>votes_useful</th>\n",
       "      <th>Cheap</th>\n",
       "      <th>Moderate</th>\n",
       "      <th>Expensive</th>\n",
       "      <th>VeryExpensive</th>\n",
       "      <th>American</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>French</th>\n",
       "      <th>...</th>\n",
       "      <th>time</th>\n",
       "      <th>really</th>\n",
       "      <th>best</th>\n",
       "      <th>love</th>\n",
       "      <th>like</th>\n",
       "      <th>service</th>\n",
       "      <th>place</th>\n",
       "      <th>good</th>\n",
       "      <th>food</th>\n",
       "      <th>great</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   votes_cool  votes_funny  votes_useful  Cheap  Moderate  Expensive  \\\n",
       "0           0            0             0      0         1          0   \n",
       "1           0            1             3      0         0          1   \n",
       "2           0            1             1      0         1          0   \n",
       "3           0            0             0      0         0          0   \n",
       "4           0            0             0      0         1          0   \n",
       "\n",
       "   VeryExpensive  American  Chinese  French  ...    time  really  best  love  \\\n",
       "0              0         1        0       0  ...       0       0     0     1   \n",
       "1              0         1        0       0  ...       1       0     1     0   \n",
       "2              0         1        0       0  ...       0       0     0     0   \n",
       "3              1         1        0       0  ...       0       1     0     0   \n",
       "4              0         1        0       0  ...       0       0     0     0   \n",
       "\n",
       "   like  service  place  good  food  great  \n",
       "0     0        0      0     1     1      0  \n",
       "1     1        1      1     1     1      1  \n",
       "2     0        0      1     1     1      0  \n",
       "3     0        1      0     0     0      0  \n",
       "4     0        0      0     0     0      0  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    text = \"\".join([ch for ch in Review[i] if ch not in string.punctuation])\n",
    "    text = re.sub('[0-9]+','',text)\n",
    "    tokens = nltk.word_tokenize(text.lower().decode('utf-8'))\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    feature = create_features(tokens,i)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid MODEL: Multinomial Naive Bayes\n",
      "\n",
      "The accuracy for this classifier is 0.723333333333\n"
     ]
    }
   ],
   "source": [
    "nb_text =  MultinomialNB().fit(X.values[train_index], train_y)\n",
    "\n",
    "text_predicted = nb_text.predict(X.values[test_index])\n",
    "\n",
    "\n",
    "print \"Hybrid MODEL: Multinomial Naive Bayes\\n\"\n",
    "\n",
    "print 'The accuracy for this classifier is ' + str(metrics.accuracy_score(test_y, text_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for this classifier is 0.723333333333\n",
      "The accuracy for this classifier is 0.716666666667\n",
      "The accuracy for this classifier is 0.706666666667\n",
      "Brier scores: (the smaller the better)\n",
      "No calibration: 0.196\n",
      "With isotonic calibration: 0.196\n",
      "With sigmoid calibration: 0.200\n"
     ]
    }
   ],
   "source": [
    "sample_weight = np.random.rand(y.shape[0])\n",
    "\n",
    "sw_train, sw_test = sample_weight[train_index], sample_weight[test_index]\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "\n",
    "clf = MultinomialNB()\n",
    "model_original = clf.fit(X.values[train_index], train_y)  # GaussianNB itself does not support sample-weights\n",
    "prob_pos_clf = clf.predict_proba(X.values[test_index])[:, 1]\n",
    "clf_predicted =model_original.predict(X.values[test_index])\n",
    "print 'The accuracy for this classifier is ' + str(metrics.accuracy_score(test_y, clf_predicted))\n",
    "\n",
    "# Naive-Bayes with isotonic calibration\n",
    "clf_isotonic = CalibratedClassifierCV(clf, cv=10, method='isotonic')\n",
    "model_isotonic = clf_isotonic.fit(X.values[train_index], train_y, sw_train)\n",
    "prob_pos_isotonic = clf_isotonic.predict_proba(X.values[test_index])[:, 1]\n",
    "isotonic_predicted = model_isotonic.predict(X.values[test_index])\n",
    "print 'The accuracy for this classifier is ' + str(metrics.accuracy_score(test_y, isotonic_predicted))\n",
    "\n",
    "# Naive-Bayes with sigmoid calibration\n",
    "clf_sigmoid = CalibratedClassifierCV(clf, cv=10, method='sigmoid')\n",
    "model_sigmoid  = clf_sigmoid.fit(X.values[train_index], train_y, sw_train)\n",
    "prob_pos_sigmoid = clf_sigmoid.predict_proba(X.values[test_index])[:, 1]\n",
    "sigmoid_predicted = model_sigmoid.predict(X.values[test_index])\n",
    "print 'The accuracy for this classifier is ' + str(metrics.accuracy_score(test_y, sigmoid_predicted))\n",
    "\n",
    "print(\"Brier scores: (the smaller the better)\")\n",
    "\n",
    "clf_score = brier_score_loss(test_y, prob_pos_clf, sw_test)\n",
    "print(\"No calibration: %1.3f\" % clf_score)\n",
    "\n",
    "clf_isotonic_score = brier_score_loss(test_y, prob_pos_isotonic, sw_test)\n",
    "print(\"With isotonic calibration: %1.3f\" % clf_isotonic_score)\n",
    "\n",
    "clf_sigmoid_score = brier_score_loss(test_y, prob_pos_sigmoid, sw_test)\n",
    "print(\"With sigmoid calibration: %1.3f\" % clf_sigmoid_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task D. Use unsupervised sentiment analysis on the reviews (with SentiStrength or any other tool) and use the sentiment scores to predict high/low rating. Compare and contrast the results of tasks B and D. What can you conclude from your analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>votes_cool</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>votes_useful</th>\n",
       "      <th>Cheap</th>\n",
       "      <th>Moderate</th>\n",
       "      <th>Expensive</th>\n",
       "      <th>VeryExpensive</th>\n",
       "      <th>American</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>...</th>\n",
       "      <th>Mexican</th>\n",
       "      <th>Thai</th>\n",
       "      <th>Vietnamese</th>\n",
       "      <th>Others</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating_final</th>\n",
       "      <th>Postive_senti</th>\n",
       "      <th>Negative_senti</th>\n",
       "      <th>Overall_senti</th>\n",
       "      <th>Pred_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Made reservations for 5:30 PM on a Saturday ni...</td>\n",
       "      <td>Low</td>\n",
       "      <td>3</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This place has an awesome Happy Hour. The envi...</td>\n",
       "      <td>High</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Noted on the OT reservation it was hubby s 50t...</td>\n",
       "      <td>Low</td>\n",
       "      <td>4</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars  votes_cool  votes_funny  votes_useful  Cheap  Moderate  Expensive  \\\n",
       "0      2           0            1             3      0         0          1   \n",
       "1      5           0            1             1      0         1          0   \n",
       "2      3           0            0             0      0         0          0   \n",
       "\n",
       "   VeryExpensive  American  Chinese     ...       Mexican  Thai  Vietnamese  \\\n",
       "0              0         1        0     ...             0     0           0   \n",
       "1              0         1        0     ...             0     0           0   \n",
       "2              1         1        0     ...             0     0           0   \n",
       "\n",
       "   Others                                             Review  Rating_final  \\\n",
       "0       0  Made reservations for 5:30 PM on a Saturday ni...           Low   \n",
       "1       0  This place has an awesome Happy Hour. The envi...          High   \n",
       "2       0  Noted on the OT reservation it was hubby s 50t...           Low   \n",
       "\n",
       "   Postive_senti  Negative_senti  Overall_senti  Pred_rating  \n",
       "0              3              -4             -1          Low  \n",
       "1              3              -1              2         High  \n",
       "2              4              -3              1         High  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export yelp_subset\n",
    "yelp_subset.to_csv('yelp_subset.csv',index=False)\n",
    "\n",
    "# Run sentistrength on column 21 of yelp_subset to get positive and negative sentiments of each review\n",
    "# Output from sentistrength: yelp_subset_senti+results.txt\n",
    "\n",
    "# Load back into python\n",
    "yelp_senti = pd.read_table('yelp_subset_senti+results.txt')\n",
    "yelp_senti['Overall_senti'] = yelp_senti['Postive_senti'] + yelp_senti['Negative_senti']\n",
    "\n",
    "# Get predicted ratings\n",
    "yelp_senti[\"Pred_rating\"] = np.where((yelp_senti['Overall_senti'] > 0),\"High\",\"Low\")\n",
    "yelp_senti[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     |      H        |\n",
      "     |      i      L |\n",
      "     |      g      o |\n",
      "     |      h      w |\n",
      "-----+---------------+\n",
      "High | <54.1%> 14.6% |\n",
      " Low |  14.2% <17.2%>|\n",
      "-----+---------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "The accuracy is: 0.712\n"
     ]
    }
   ],
   "source": [
    "# Checking accuracy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = yelp_senti['Rating_final'].tolist()\n",
    "y_pred = yelp_senti['Pred_rating'].tolist()\n",
    "cm_sk = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "cm = nltk.ConfusionMatrix(y_true, y_pred)\n",
    "print (cm.pretty_format(sort_by_count=True, show_percents=True))\n",
    "print 'The accuracy is:',round(float(cm_sk[1][1]+cm_sk[0][0])/float(sum(cm_sk)),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task E. Implement the PMI approach to sentiment analysis (in either Python or R), and run the classification model with the sentiment scores. How do your results compare with those in Task D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "from nltk.corpus import stopwords as stp\n",
    "from nltk import pos_tag\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def features_extraction(text, rule_1, rule_2, no_match):\n",
    "    \n",
    "    wc = []\n",
    "    append = wc.append\n",
    "    text = text.lower()\n",
    "    tokens = re.split(\"\\W+\", text)\n",
    "    stopwords = stp.words(\"english\")\n",
    "    remove = tokens.remove\n",
    "    while \"\" in tokens:\n",
    "        remove(\"\")\n",
    "    for token in tokens:\n",
    "        if token in stopwords:\n",
    "            remove(token)\n",
    "    token_pos = pos_tag(tokens)\n",
    "    \n",
    "    for i in xrange(len(token_pos)-1):\n",
    "        if (token_pos[i][1], token_pos[i+1][1]) not in rule_1 and\\\n",
    "            (token_pos[i][1], token_pos[i+1][1]) not in rule_2:\n",
    "                continue\n",
    "        elif (token_pos[i][1], token_pos[i+1][1]) in rule_1:\n",
    "            append((token_pos[i][0], token_pos[i+1][0]))\n",
    "        elif (token_pos[i][1], token_pos[i+1][1]) in rule_2:\n",
    "            try:\n",
    "                if token_pos[i+2] not in no_match:\n",
    "                    append((token_pos[i][0], token_pos[i+1][0]))\n",
    "            except IndexError:\n",
    "                append((token_pos[i][0], token_pos[i+1][0]))\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Semantic_Orientation(phrases,positive=\"excellent\", negative=\"poor\", prior = 1,engine=\"google\",distance=10,threshold=None):\n",
    "  \n",
    "    so_positive = 0.01\n",
    "    so_negative = 0.01\n",
    "    so_avg = 0\n",
    "    get = requests.get\n",
    "\n",
    "    engine.lower() == \"google\"\n",
    "    url = \"http://www.google.com/search?q=%s\"\n",
    "    id_pattern = \"resultStats\"\n",
    "    \n",
    "    for phrase in phrases:\n",
    "        term = \"%22{}+{}%22+AROUND({})+%22{}%22\".format(phrase[0], distance, phrase[1], positive)\n",
    "        page = get(url % term)\n",
    "        soup = BeautifulSoup(page.text, \"lxml\")\n",
    "        try:\n",
    "            rtr_pos = int(\"\".join(re.split(\"\\D+\",soup.find(\"div\", id=id_pattern).get_text().encode(\"utf-８\"))))\n",
    "        except AttributeError:\n",
    "            rtr_pos = 0\n",
    "            \n",
    "        # if rtr_pos == None:\n",
    "        #     rtr_pos = 0\n",
    "        \n",
    "        term = \"%22{}+{}%22+AROUND({})+%22{}%22\".format(phrase[0], distance, phrase[1], negative)\n",
    "        page = get(url % term)\n",
    "        soup = BeautifulSoup(page.text, \"lxml\")\n",
    "        try:\n",
    "            rtr_neg = int(\"\".join(re.split(\"\\D+\",soup.find(\"div\", id=id_pattern).get_text().encode(\"utf-８\"))))\n",
    "        except AttributeError:\n",
    "            rtr_neg = 0\n",
    "            \n",
    "        # if rtr_neg == None:\n",
    "         #   rtr_neg =0\n",
    "            \n",
    "        so_positive += rtr_pos\n",
    "        so_negative += rtr_neg\n",
    "        \n",
    "        so_avg += math.log(so_positive/so_negative/prior)\n",
    "    \n",
    "    #if len(phrases)==0:\n",
    "     #   so_avg=0\n",
    "    #else:\n",
    "        so_avg = so_avg*1.0/len(phrases)\n",
    "    \n",
    "    if threshold == None:\n",
    "        return so_avg\n",
    "    else:\n",
    "        return int(so_avg>threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Defining Patters for Feature Extraction\n",
    "rule_1 = [(\"JJ\", \"NN\"), (\"JJ\", \"NNS\"), (\"RB\", \"VB\"), (\"RB\", \"VBD\"), (\"RB\", \"VBN\"), (\"RB\", \"VBG\"),(\"RBR\", \"VB\"), (\"RBR\", \"VBD\"), (\"RBR\", \"VBN\"), (\"RBR\", \"VBG\"),\n",
    "          (\"RBS\", \"VB\"), (\"RBS\", \"VBD\"), (\"RBS\", \"VBN\"), (\"RBS\", \"VBG\")]\n",
    "rule_2 = [(\"RB\", \"JJ\"), (\"RBR\", \"JJ\"), (\"RBS\", \"JJ\"),(\"JJ\", \"JJ\"),(\"NN\", \"JJ\"), (\"NNS\", \"JJ\")]\n",
    "no_match = [\"NN\", \"NNS\"]\n",
    "\n",
    "# Extracting Features\n",
    "\n",
    "features_extract = functools.partial(features_extraction, rule_1=rule_1, rule_2=rule_2, no_match=no_match)\n",
    "features=yelp_subset.Review.map(features_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-e220bb4cacc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Mapping the function to our review list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOpinion_Orientation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\rache\\Anaconda2\\lib\\site-packages\\pandas\\core\\series.pyc\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, arg, na_action)\u001b[0m\n\u001b[0;32m   2102\u001b[0m             \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malgos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2104\u001b[1;33m             \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2106\u001b[0m         return self._constructor(new_values,\n",
      "\u001b[1;32mpandas\\src\\inference.pyx\u001b[0m in \u001b[0;36mpandas.lib.map_infer (pandas\\lib.c:62658)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-562fcff0a132>\u001b[0m in \u001b[0;36mSemantic_Orientation\u001b[1;34m(phrases, positive, negative, prior, engine, distance, threshold)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"lxml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mrtr_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\D+\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"div\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mid_pattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-８\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mrtr_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "# Calling the function that gives Semantic Orientation for a review.\n",
    "\n",
    "Opinion_Orientation = functools.partial(Semantic_Orientation,positive=\"excellent\", negative=\"poor\",prior = 1,engine=\"google\",distance=5,threshold=None)\n",
    "\n",
    "# Mapping the function to our review list(sample :12)\n",
    "\n",
    "prediction = features[:12].map(Opinion_Orientation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-47294d0b2af1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Checking accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prediction' is not defined"
     ]
    }
   ],
   "source": [
    "# Checking accuracy\n",
    "y_pred = prediction.tolist()\n",
    "y_true = y[:12].tolist() \n",
    "\n",
    "\n",
    "cm_sk = confusion_matrix(y_true, y_pred)\n",
    "cm = nltk.ConfusionMatrix(y_true, y_pred)\n",
    "\n",
    "\n",
    "print (cm.pretty_format(sort_by_count=True, show_percents=True))\n",
    "if cm_sk[1][1] ==None:\n",
    "    sum_sk[1][1]=0;\n",
    "print 'The accuracy is:',round(float(cm_sk[1][1]+cm_sk[0][0])/float(len(y_pred)),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task F. What are the top 5 “attributes” of a restaurant that are associated with (i) high and (ii) low ratings? That is, when people rate a restaurant high or low, are they more likely to mention service, ambiance, etc.? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Tokenization on the positive reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_reviews  = yelp.ix[yelp.rating == 'High']['Review']\n",
    "corpus = pos_reviews.str.cat(sep=' ')\n",
    "corpus = corpus.decode('utf-8')\n",
    "corpus_words = nltk.word_tokenize(corpus.lower())\n",
    "corpus_words = [word for word in corpus_words if word.isalpha()==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete stop words and keep only nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_words_sw = [word for word in corpus_words if word not in stopwords.words('english')]\n",
    "filtered_poi = nltk.pos_tag(filtered_words_sw)\n",
    "noun = [x[0] for x in filtered_poi if x[1] == 'NN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the 5 most common nouns in the corpurs, and they are the top attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'food', 10462),\n",
       " (u'place', 8816),\n",
       " (u'service', 4405),\n",
       " (u'time', 4148),\n",
       " (u'restaurant', 2711)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun = nltk.FreqDist(noun)\n",
    "noun.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform same analysis on negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neg_reviews  = yelp.ix[yelp.rating == 'Low']['Review']\n",
    "neg_corpus = neg_reviews.str.cat(sep=' ')\n",
    "neg_corpus = neg_corpus.decode('utf-8')\n",
    "neg_corpus_words = nltk.word_tokenize(neg_corpus.lower())\n",
    "neg_corpus_words = [word for word in neg_corpus_words if word.isalpha()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_words_sw = [word for word in neg_corpus_words if word not in stopwords.words('english')]\n",
    "neg_poi = nltk.pos_tag(neg_words_sw)\n",
    "neg_noun = [x[0] for x in neg_poi if x[1] == 'NN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'food', 6574),\n",
       " (u'place', 4370),\n",
       " (u'service', 2665),\n",
       " (u'time', 2413),\n",
       " (u'order', 1788)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_noun = nltk.FreqDist(neg_noun)\n",
    "neg_noun.most_common(5)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
